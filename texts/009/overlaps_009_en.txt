A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
Although computer models support this method, Kish thinks the movement is unnatural.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
But no one knew exactly how blind people did this.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
But the panel doesn’t work for everyone at first.
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
Curious as to what they were, he climbed over the fence and spent much of his night investigating.
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it?
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
Experiencing echolocation
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
Few people know that this same technique can work for human beings.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
For example, in one scene, he was playing a video game that required destroying objects entering the scene.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
For example, your eyes move in the direction of a sudden noise.
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
He can’t really say whether his experience is like seeing.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
He has no memory of having eyesight.
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it?
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
He never used a guide dog, a white cane or his hands.
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
His saccadic eye movements corresponded to the changes in location of the virtual objects.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
How does he do it?
How does he do it? Kish is a human echolocator, a real life Daredevil.
How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment.
How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings.
How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information.
How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says.
How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
How the human brain adapts to blindness and allows us to see our world through echolocation.
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell.
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person.
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it?
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil.
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment.
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings.
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information.
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says.
How the human brain adapts to blindness and allows us to see our world through echolocation. Daniel Kish has been blind since he was 13 months old, but you wouldn’t be able to tell. He navigates crowded streets on his bike, camps out in the wilderness, swims, dances and does other activities many would think impossible for a blind person. How does he do it? Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
I don’t remember learning this, he says.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
Is it highly solid or sparse? and Is it highly reflective or absorbent?
Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
Is sound alone responsible for echolocators’ ability to navigate the environment?
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
It seems possible that echolocators have visual imagery that is similar to that of sighted people.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
It’s a tough-love approach with very little hand-holding.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
Kish is a human echolocator, a real life Daredevil.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
Kish is a human echolocator, a real life Daredevil. Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
Kish lost his first eye at 7 months and the other at 13 months.
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
Kish says all those patterns come back as acoustic imprints.
Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
Kish then changes the cane his students use during walking.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
Laser treatments are performed to kill them off, followed by chemotherapy.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
Left, Daniel Kish takes the lead on a tandem bike ride.
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
Notice the term detection isn’t included.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
One example of this restriction is the traditional cane training method.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
One study showed that the blind and the sighted scored similarly on normal hearing tests.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
Only a small fraction of an entire scene falls on the fovea at any given time.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
PAD
Participants were rewarded for learning to detect the board by not walking into it face-first.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
Perhaps what is most amazing about echolocation is that it can be taught.
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
Research shows we can perceive these types of stimuli subconsciously.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
Right, Ben Underwood, shown in 2006, plays basketball with a friend.
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
Saccades are the quick, coordinated movements of both eyes to a focal point.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
Seeing with Your Ears
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
Several sighted instructors are in training, showing promise of using echolocation themselves.
Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
Shocked by his statement, his mother responded, I see the building, but do you see it?
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
So why don’t all blind people echolocate?
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
Students answer questions such as, Is the object coarse or smooth?
Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
Teaching the Blind to See
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears.
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate?
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens.
The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill. Now, through his organization, World Access for the Blind, he strives to give the blind nearly the same freedom as sighted people by teaching blind people to navigate with their ears. So why don’t all blind people echolocate? The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene. Although echolocation didn’t give him the ability to see the images on a flat screen, Ben could play games based on the sound effects played through the television’s speakers. Like many blind people, Ben used the sound cues to figure out where objects were on the screen. His saccadic eye movements corresponded to the changes in location of the virtual objects. The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received.
The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place. And some individuals who have gone blind later in life describe the experience as visual, in terms of flashes, shadows or bright experiences. It seems possible that echolocators have visual imagery that is similar to that of sighted people. Ben’s case provides some evidence of this, as he consistently reported seeing the objects he could detect, not just hearing them. And while self-reports are notoriously unreliable, there is other evidence that Ben really could see with his ears. Ben had prosthetic eyes that replaced his real ones, but since his eye muscles were still intact, the prosthesis moved in different directions, much like real eyes. In the documentary Extraordinary People: The Boy Who Sees Without Eyes, it’s clear Ben’s prosthetic eyes were making saccades in several situations that require focusing quickly on different objects in the peripheral field. Saccades are the quick, coordinated movements of both eyes to a focal point. The documentary never discussed Ben’s saccadic eye movements, but there’s no doubt they occurred and that they matched the auditory stimuli he received. For example, in one scene, he was playing a video game that required destroying objects entering the scene.
The key is to notice the changes in the sound when it comes back from when it went out.
The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
The next set of exercises helps students learn how to determine what the objects actually are.
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
The primary role of saccadic eye movements is to guarantee high resolution in vision.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
The primary role of saccadic eye movements is to guarantee high resolution in vision. We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
The problem, says Kish, is that our society has fostered restricting training regimens.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
The problem, says Kish, is that our society has fostered restricting training regimens. One example of this restriction is the traditional cane training method. The military developed the cane techniques more than 60 years ago for blind veterans, people used to living in restricted circumstances. Kish’s training curriculum differs from tradition by taking an immersive approach intended to activate environmental awareness. It’s a tough-love approach with very little hand-holding. He encourages children to explore their home environment for themselves and discourages family members from interfering unless the child otherwise could be harmed. Kish then changes the cane his students use during walking. The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are. This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
The student holds the cane out in front, elbow slightly bent, so the hand is roughly at waist height. With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
The student repeatedly taps the cane from left to right, called two-point touch.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people.
Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created. The researchers concluded that the subjects relied on sound emanating from their shoes, implying sound is responsible for navigational ability. The increased ability to navigate via sound appears to be the result of sound processing in the brain, not merely increased acuity of hearing. One study showed that the blind and the sighted scored similarly on normal hearing tests. But when a recording had echoes, parts of the brain associated with visual perception in sighted people activated in echolocators but not in sighted people. These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler. The next set of exercises helps students learn how to determine what the objects actually are.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught.
These results showed how echolocators extracted information from sound that wasn’t available to the sighted controls. Some reports seem to indicate that humans can’t perceive objects that are very close — within 2 meters of them — through echolocation. But a 1962 study by Kellogg at Florida State University showed that blind people can detect obstacles at much shorter distances — 30 to 120 centimeters. Some participants were accurate even within 10 centimeters, suggesting that although subjects aren’t consciously aware of the echo, they still can respond appropriately to echo stimuli. The above cases show that our perceptual experiences involve a lot more than just what we’re consciously aware of. Our brain is primed to accomplish the seemingly superhuman, even at the basic level of perception. It’s an extraordinary organ that creates our rich experiences by turning waves that merely strike the eardrum into complicated, phenomenal representations of our surroundings. Teaching the Blind to See Perhaps what is most amazing about echolocation is that it can be taught. Kish wrote his developmental psychology master’s thesis on the subject, developing the first systematic approach to teaching the skill.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface.
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth?
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent?
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints.
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out.
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli.
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
This essentially involves three characteristics: where things are, how large they are and depth of structure, which refers to the geometric nature of the object or surface. Students answer questions such as, Is the object coarse or smooth? Is it highly solid or sparse? and Is it highly reflective or absorbent? Kish says all those patterns come back as acoustic imprints. The key is to notice the changes in the sound when it comes back from when it went out. With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
This left Ben completely blind.
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there?
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it?
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building.
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue.
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
This left Ben completely blind. A couple of years later, when Ben was in the back seat of the car with the window down, he suddenly said, Mom, do you see that tall building there? Shocked by his statement, his mother responded, I see the building, but do you see it? It turned out Ben had picked up on the differences in sounds coming from empty space versus a tall building. When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
Unfortunately, the tumors cannot be separated from the retina.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina.
Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind. Kish lost his first eye at 7 months and the other at 13 months. He has no memory of having eyesight. His earliest vivid memory is from when he was very young, maybe 2½. He climbed out his bedroom window and walked over to a chain-link fence in his backyard. Curious as to what they were, he climbed over the fence and spent much of his night investigating. Like Kish, Ben Underwood was a self-taught echolocator and was also diagnosed with bilateral retinoblastomas, in his case at the age of 2. After many failed attempts to save his vision by treating the tumors with radiation and chemotherapy, his mother made the difficult decision to remove her son’s right eye and left retina. This left Ben completely blind.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy.
Using a technique similar to what bats and dolphins use, human echo-locators navigate using audio cues given off by reflective surfaces in the environment. Few people know that this same technique can work for human beings. But as a matter of fact, echolocation comes quite naturally to people like Kish, who are deprived of visual information. I don’t remember learning this, he says. My earliest memories were of detecting things and noting what they might have reminded me of and then going to investigate. Kish was born with bilateral retinoblastomas, tiny cancers of the retina, which is part of the eye responsible for sensing visual information. Tumors form early in this type of cancer, so aggressive treatment is necessary to ensure they don’t metastasize to the rest of the body. Unfortunately, the tumors cannot be separated from the retina. Laser treatments are performed to kill them off, followed by chemotherapy. The result is that the retina is destroyed along with the cancer, meaning patients often are left completely blind.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained.
Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds. But no one knew exactly how blind people did this. And although bat echolocation was documented in 1938, scientists didn’t become seriously interested in the phenomenon until the early years of the Cold War, when military funding made the research feasible. It turns out human echolocation is akin to active sonar and the kind of echolocation used by dolphins and bats, but less fine-grained. While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
We are not robots, he says.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
We can see with high resolution only when images from the visual field fall on the retina’s central region, called the fovea. When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes.
What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first. After multiple trials, both the blindfolded and blind subjects became better able to detect the obstacle. After about 30 trials, blindfolded subjects were as successful at stopping in front of the boards as blind subjects when they were wearing hard-soled shoes. But this ability disappeared when subjects performed the same experiments on carpet or while wearing socks, which muffled the sound their footsteps created.
When Ben was in school, he started clicking with his tongue.
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects.
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do.
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands.
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned.
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride.
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend.
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision.
When Ben was in school, he started clicking with his tongue. At first it was an idle habit, but then he realized he could use the skill to detect the approximate shape, location and size of objects. Soon, Ben was riding a bicycle, skateboarding, playing video games, walking to school and doing virtually anything else an ordinary boy his age could do. He never used a guide dog, a white cane or his hands. Very sadly, Ben passed away in 2009 after the cancer that claimed his eyes returned. Left, Daniel Kish takes the lead on a tandem bike ride. Right, Ben Underwood, shown in 2006, plays basketball with a friend. Experiencing echolocation For centuries, researchers have been trying to find out how blind people compensate for their loss of vision. It was clear that some blind people occasionally were able to hear objects that were apparently making no sounds.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
When images fall on the more peripheral areas of the retina, we don’t see them very clearly. Only a small fraction of an entire scene falls on the fovea at any given time. But rapid eye movements can ensure that you look at many parts of an entire scene in high resolution. Although it’s not immediately apparent, the brain creates a persisting picture based on many individual snapshots. Many other factors govern eye movements, including changes in and beliefs about the environment, and intended action. For example, your eyes move in the direction of a sudden noise. Even when recalling visual imagery and there is no sensory input or external environment to process, saccadic eye movements still occur. This happens because when the brain stores information about the environment, it stores information about eye movements along with it. When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
When we do hear echoes, it’s from sound bouncing back off distant objects.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis. His research showed that both blind and sighted subjects wearing blindfolds could learn to detect objects in the environment through sound, and a study by another researcher showed that, with some training, both blind and sighted individuals can precisely determine certain properties of objects, such as distance, size, shape, substance and relative motion from sound alone. While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
When your brain generates a visual image, it’s likely a composite of different snapshots of reality, and rapid eye movements help keep the visual image organized and in focus. This dual storage mechanism explains Ben’s saccadic eye movements: The sound stimuli from Ben’s environment triggered his brain to generate spatial imagery matching the sound stimuli, and his saccadic eye movements helped keep the image organized and in focus. Seeing with Your Ears Sighted people often use a simple form of echolocation, too, perhaps without even realizing it. When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs.
When you’re hanging a picture on a wall, one way to locate a stud within it is to knock around and listen for changes in pitch. But when you tap on a hollow space in the wall, you usually don’t hear an actual echo — yet you can tell somehow that the space sounds hollow. Research shows we can perceive these types of stimuli subconsciously. When we do hear echoes, it’s from sound bouncing back off distant objects. When you click your tongue or whistle toward a nearby object, though, the echo returns so fast that it overlaps the original sounds, making it hard to hear an echo. But the brain unconsciously interprets the combination of the sound thrown in one direction and the returning sound as an alteration in pitch. What makes Ben and Kish so remarkable is that they can use what everyone’s brain unconsciously detects in an active way to navigate the world. And although Ben and Kish may seem superhuman because of their perceptual abilities, research confirms that sighted humans can acquire echolocation, too. After all, the visual cortex does process some sounds, particularly when the brain seeks to match auditory and visual sensory inputs. American psychologist Winthrop Niles Kellogg began his human-echolocation research program around the time of the Cuban Missile Crisis.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people.
While bats can locate objects as small as flies, human echolocators report that objects must be much larger — about the size of a water glass — for them to be locatable. Philosophers and neuroscientists often talk about phenomenology, or what it’s like to have an experience. If we show you a red ball and ask you about its color, assuming you’re not colorblind, it should be easy for you to answer red. However, if we ask you to describe what it’s like to see the color red, you’d have a much harder time answering. By their very nature, questions about phenomenology can be nearly impossible to answer, making it hard to discover exactly what it’s like to experience echolocation. Indeed, Kish says that, because he has been blind for as long as he can remember, he has nothing to compare his experience to. He can’t really say whether his experience is like seeing. However, he says he definitely has spatial imagery, which has the properties of depth and dimension. Research indicates that the imagery of echolocation is constructed by the same neurology that processes visual data in sighted people. The information isn’t traveling down the optic pathway — the connection from the eyes to the brain — but it ends up in the same place.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment?
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances.
While sighted individuals show some ability to echolocate, Kellogg showed that blind echolocators seem to operate a bit differently when collecting sensory data. They move their heads in different directions when spatially mapping an environment, while sighted subjects don’t move their heads when given the same types of tasks. Interestingly, when sighted individuals are deprived of visual sensory information for an extended period of time, they naturally start echolocating, possibly after only a few hours of being blindfolded. What’s more, with their newfound echolocation skills comes some visual imagery. After a week of being blindfolded, the imagery becomes more vivid. One of Kellogg’s research participants said he experienced ornate buildings of whitish green marble and cartoon-like figures. Is sound alone responsible for echolocators’ ability to navigate the environment? Researchers wonder whether touch cues, such as the way air moves around objects, can offer information about the surroundings. Philip Worchel and Karl Dallenbach from the University of Texas at Austin sought to answer these questions in the 1940s. Their experiments involved asking both blind and blindfolded sighted participants to walk toward a board placed at varying distances. Participants were rewarded for learning to detect the board by not walking into it face-first.
With determined practice, students eventually learn how to differentiate among general environmental stimuli.
With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well.
With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves.
With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences.
With determined practice, students eventually learn how to differentiate among general environmental stimuli. Although the organization’s instructors are currently all blind echolocators, Kish anticipates that sighted instructors could teach the skill as well. Several sighted instructors are in training, showing promise of using echolocation themselves. His goal is to have sighted instructors performing just as well as blind echolocators, though he emphasizes that although both sighted and blind individuals can echolocate, they may have profoundly different phenomenological experiences. In the meantime, Kish is hard at work, teaching the blind how to use their ears to see.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
With every step, the cane tip lands about where the student’s foot will land so the cane clears the area of where the child is about to step. The student repeatedly taps the cane from left to right, called two-point touch. Although computer models support this method, Kish thinks the movement is unnatural. We are not robots, he says. The reality is that the biomechanics do not sustain the kind of regimented movement you have to have in order for that to work — you lose fluidity of motion. You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality.
You don’t have to be a physical therapist to know that’s a recipe for a wrist problem. Then the real fun begins: The students learn to echolocate by systematic stimulus differentiation. Notice the term detection isn’t included. No stimulus really occurs in a vacuum, so the process is not so much detection as it is distinguishing one stimulus from another and its background. The process follows a standard learning structure: Students first learn to differentiate among strong, obvious stimuli and then advance to weaker, less obvious stimuli. Kish establishes a hook stimulus by using a plain panel he moves around in the student’s environment. Students don’t need to know what they’re listening for, since the stimulus is selected to be strong enough that it captures the brain’s attention. But the panel doesn’t work for everyone at first. In those cases, he uses a 5-gallon bucket or something else that produces a very distinct sound quality. Once the brain is hooked on the characteristic stimulus, he starts manipulating its features to make the effect subtler.
